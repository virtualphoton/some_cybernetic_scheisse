{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import cv2.aruco as aruco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video2\n",
      "video3\n"
     ]
    }
   ],
   "source": [
    "!ls /dev | grep video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_id = 2\n",
    "capture = cv2.VideoCapture(cam_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = (1280, 720)\n",
    "res_x, res_y = res\n",
    "capture.set(3, res_x)\n",
    "capture.set(4, res_y)\n",
    "capture.set(cv2.CAP_PROP_FOURCC, cv2.VideoWriter_fourcc(*\"MJPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_path(path):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return path\n",
    "    raise ValueError(\"File Exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "TILE_SIZE = .2391 / 8\n",
    "MARKER_SIZE = TILE_SIZE * 23 / 30\n",
    "\n",
    "\n",
    "class Camera:\n",
    "\n",
    "    def __init__(self, tile_size=TILE_SIZE, marker_size=MARKER_SIZE,\n",
    "                 board_size=(5, 8),):\n",
    "        self.captured_images = []\n",
    "\n",
    "        self.dictionary = aruco.getPredefinedDictionary(aruco.DICT_4X4_50)\n",
    "        self.parameters = aruco.DetectorParameters()\n",
    "        self.charuco_params = aruco.CharucoParameters()\n",
    "\n",
    "        self.tile_size = tile_size\n",
    "        self.board = aruco.CharucoBoard(board_size, self.tile_size, marker_size,\n",
    "                                        self.dictionary)\n",
    "        self.board.setLegacyPattern(True)\n",
    "        self.detector = aruco.CharucoDetector(\n",
    "            self.board, self.charuco_params, self.parameters)\n",
    "\n",
    "        self.mtx, self.dist = None, None\n",
    "        self.captured_images = []\n",
    "        self.last_time = 0\n",
    "\n",
    "    def add_frame(self, image) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        returns RGBA array of size (x, y, 4)\n",
    "        \"\"\"\n",
    "        image0 = image\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        cur_corners, cur_ids, _ = self.detector.detectMarkers(image)\n",
    "\n",
    "        if time.time() - self.last_time < 0.5:\n",
    "            cv2.circle(image0, (1150, 700), 10, (255, 255, 0),\n",
    "                       int(np.sin(time.time() - self.last_time) * 40) + 1)\n",
    "        elif len(cur_corners) >= 19:\n",
    "            cv2.circle(image0, (1200, 700), 10, (255, 255, 0), 2)\n",
    "            self.captured_images.append(image0.copy())\n",
    "            self.last_time = time.time()\n",
    "\n",
    "        cv2.putText(image0, f\"{len(cur_corners):02d}\",\n",
    "                    (64, 64), font, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "        return image0\n",
    "\n",
    "    def load_coeffs(self):\n",
    "        # self.mtx = np.array([[1.11297931e+03, 0.00000000e+00, 6.40000000e+02],\n",
    "        #                      [0.00000000e+00, 1.11297931e+03, 3.60000000e+02],\n",
    "        #                      [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "        # self.dist = np.zeros((1, 5))\n",
    "        self.mtx = np.array([[1.00604718e+03, 0.00000000e+00, 6.35524500e+02],\n",
    "                             [0.00000000e+00, 1.00242528e+03, 3.65893138e+02],\n",
    "                             [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])\n",
    "        self.dist = np.array(\n",
    "            [[0.12490427, -0.38032263, -0.00073625, -0.00364679,  0.34870377]])\n",
    "\n",
    "    def calibrate(self):\n",
    "        matched_points = []\n",
    "        for image in self.captured_images:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            cur_corners, cur_ids, *_ = self.detector.detectBoard(image)\n",
    "            if cur_ids is not None:\n",
    "                matched_points.append(list(\n",
    "                    map(np.squeeze, self.board.matchImagePoints(\n",
    "                        cur_corners, cur_ids.flatten()))\n",
    "                ))\n",
    "        obj_points, img_points = zip(*matched_points)\n",
    "        print(obj_points[1].shape, len(img_points),\n",
    "              obj_points[0].shape, img_points[0].shape)\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "            obj_points, img_points, image.shape,\n",
    "            None, None\n",
    "        )\n",
    "        self.mtx = mtx\n",
    "        self.dist = dist\n",
    "        print()\n",
    "        print(self.mtx, self.dist)\n",
    "        print()\n",
    "\n",
    "    def process_charuko(self, frame):\n",
    "        assert self.mtx is not None and self.dist is not None\n",
    "\n",
    "        frame = frame.copy()\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        *_, corners, ids = self.detector.detectBoard(gray)\n",
    "\n",
    "        if not len(corners):\n",
    "            # cv2.putText(frame, \"No Ids\", (0,64), font, 1, (0,255,0),2,cv2.LINE_AA)\n",
    "            return frame, None, None\n",
    "\n",
    "        _, corners_checker, ids_checker = aruco.interpolateCornersCharuco(\n",
    "            corners, ids,\n",
    "            gray, self.board\n",
    "        )\n",
    "\n",
    "        _, rvec_check, tvec_check = aruco.estimatePoseCharucoBoard(\n",
    "            corners_checker, ids_checker,\n",
    "            self.board, self.mtx, self.dist,\n",
    "            None, None\n",
    "        )\n",
    "        try:\n",
    "            cv2.drawFrameAxes(frame, self.mtx, self.dist,\n",
    "                              rvec_check, tvec_check, 0.1)\n",
    "        except:\n",
    "            pass\n",
    "        # print(rvec_check, tvec_check)\n",
    "        aruco.drawDetectedMarkers(frame, corners)\n",
    "        rvecs, tvecs, _ = aruco.estimatePoseSingleMarkers(\n",
    "            corners, self.tile_size / 2, self.mtx, self.dist)\n",
    "        # print()\n",
    "        # print(rvecs[0], tvecs[0])\n",
    "\n",
    "        for rvec, tvec in zip(rvecs, tvecs):\n",
    "            cv2.drawFrameAxes(frame, self.mtx, self.dist, rvec, tvec, 0.01)\n",
    "\n",
    "        return frame, rvec_check, tvec_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(\"./data/images_1.npy\", \"rb\") as f:\n",
    "#     calibr.captured_images.extend(list(np.load(f)))\n",
    "# with open(\"./data/images_2.npy\", \"rb\") as f:\n",
    "#     calibr.captured_images.extend(list(np.load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from websocket import create_connection\n",
    "import json\n",
    "def get_pos():\n",
    "    req = {\"command\": \"get_xyz\", \"args\":[], \"kwargs\":{}}\n",
    "    data = json.dumps(req)\n",
    "    ws = create_connection(\"ws://localhost:9001\")\n",
    "    ws.send(data)\n",
    "    res = json.loads(ws.recv())\n",
    "    ws.close()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_effector_poses = []\n",
    "cam_to_checkers = []\n",
    "\n",
    "\n",
    "def append_ef(xyz):\n",
    "    x, y, z = np.array(xyz) / 1000\n",
    "    alpha = np.arctan2(y, x)\n",
    "    matrix = np.array([[np.cos(alpha), -np.sin(alpha), 0, x],\n",
    "                       [np.sin(alpha), np.cos(alpha), 0, y],\n",
    "                       [0, 0, 1, z],\n",
    "                       [0, 0, 0, 1]])\n",
    "    end_effector_poses.append(matrix)\n",
    "\n",
    "def get_twist(R, p):\n",
    "    return np.block([[R, p.reshape(-1, 1)], [0] * len(p) + [1]])\n",
    "    \n",
    "def append_cam2checker(rvec, tvec):\n",
    "    cam_to_checkers.append(get_twist(cv2.Rodrigues(rvec)[0], tvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from eye_hand_calibration import get_board2base_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capture.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _stream():\n",
    "    displaying_aruco = False\n",
    "    while True:\n",
    "        _, cam_img = capture.read()\n",
    "        if not displaying_aruco:\n",
    "            cv2.imshow('w', cam_img)\n",
    "        else:\n",
    "            cv2.imshow('w', calibr.process_charuko(cam_img.copy())[0])\n",
    "        \n",
    "        if (key := cv2.waitKey(1)) == ord(\"q\"):\n",
    "            break\n",
    "        elif key == ord(\"n\"):\n",
    "            displaying_aruco = not displaying_aruco\n",
    "        elif key == ord(\"f\"):\n",
    "            _, rvec, tvec = calibr.process_charuko(cam_img.copy())\n",
    "            xyz = get_pos()[\"result\"]\n",
    "            append_cam2checker(rvec, tvec)\n",
    "            append_ef(xyz)\n",
    "def stream():\n",
    "    try:\n",
    "        _stream()\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr = Camera(board_size=(5, 8))\n",
    "calibr.load_coeffs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /home/conda/feedstock_root/build_artifacts/libopencv_1694892514749/work/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m stream()\n",
      "Cell \u001b[0;32mIn[22], line 21\u001b[0m, in \u001b[0;36mstream\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstream\u001b[39m():\n\u001b[1;32m     20\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 21\u001b[0m         _stream()\n\u001b[1;32m     22\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m         cv2\u001b[39m.\u001b[39mdestroyAllWindows()\n",
      "Cell \u001b[0;32mIn[22], line 6\u001b[0m, in \u001b[0;36m_stream\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m _, cam_img \u001b[39m=\u001b[39m capture\u001b[39m.\u001b[39mread()\n\u001b[1;32m      5\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m displaying_aruco:\n\u001b[0;32m----> 6\u001b[0m     cv2\u001b[39m.\u001b[39;49mimshow(\u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m, cam_img)\n\u001b[1;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m      8\u001b[0m     cv2\u001b[39m.\u001b[39mimshow(\u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, calibr\u001b[39m.\u001b[39mprocess_charuko(cam_img\u001b[39m.\u001b[39mcopy())[\u001b[39m0\u001b[39m])\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /home/conda/feedstock_root/build_artifacts/libopencv_1694892514749/work/modules/highgui/src/window.cpp:971: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'imshow'\n"
     ]
    }
   ],
   "source": [
    "stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "cam_id = \"http://192.168.43.1:8021/video\"\n",
    "capture = cv2.VideoCapture(cam_id)\n",
    "calibr = Camera(board_size=(5, 8))\n",
    "calibr.load_coeffs()\n",
    "\n",
    "stream()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_path(\"0.npy\").open(\"wb\") as f:\n",
    "    np.save(f, end_effector_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_path(\"checker.npy\").open(\"wb\") as f:\n",
    "    np.save(f, cam_to_checkers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in cam_to_checkers:\n",
    "    np.linalg.inv(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in end_effector_poses:\n",
    "    np.linalg.inv(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': [-18.81871223449707, 227.0407257080078, -20.088851928710938]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tr_pred \u001b[39m=\u001b[39m get_board2base_transform(end_effector_poses, cam_to_checkers)\n",
      "File \u001b[0;32m~/Documents/ML/some_cybernetic_scheisse/machines/02_dobot/camera/../eye_hand_calibration.py:16\u001b[0m, in \u001b[0;36mget_board2base_transform\u001b[0;34m(twists_base2endeffector, twists_board2camera)\u001b[0m\n\u001b[1;32m     14\u001b[0m lefts, rights \u001b[39m=\u001b[39m [], []\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m i, j \u001b[39min\u001b[39;00m combinations(np\u001b[39m.\u001b[39marange(\u001b[39mlen\u001b[39m(base_to_end)), \u001b[39m2\u001b[39m):\n\u001b[0;32m---> 16\u001b[0m     lefts\u001b[39m.\u001b[39mappend((np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(As[j]) \u001b[39m@\u001b[39m As[i])[:\u001b[39m2\u001b[39m])\n\u001b[1;32m     17\u001b[0m     rights\u001b[39m.\u001b[39mappend((Bs[j] \u001b[39m@\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(Bs[i])))\n\u001b[1;32m     19\u001b[0m left \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mvstack(lefts)\n",
      "File \u001b[0;32m~/anaconda3/envs/robotict/lib/python3.11/site-packages/numpy/linalg/linalg.py:561\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m    559\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    560\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[0;32m--> 561\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[1;32m    562\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[0;32m~/anaconda3/envs/robotict/lib/python3.11/site-packages/numpy/linalg/linalg.py:112\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[0;32m--> 112\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "tr_pred = get_board2base_transform(end_effector_poses, cam_to_checkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def get_path(path):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        return path\n",
    "    raise ValueError(\"File Exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "capture.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(calibr.captured_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr.calibrate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.cvtColor(cam_img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_corners, cur_ids, _ = detector.detectMarkers(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cur_corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "_, cam_img = capture.read()\n",
    "plt.imshow(cam_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(calibr.process_charuko(cam_img)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disl_charuco():\n",
    "    displaying = np.array([])\n",
    "    try:\n",
    "        while True:\n",
    "            _, cam_img = capture.read()\n",
    "            \n",
    "            if not displaying.size:\n",
    "                cv2.imshow('w', cam_img)\n",
    "            else:\n",
    "                cv2.imshow('w', displaying)\n",
    "            if (key := cv2.waitKey(1)) == ord(\"q\"):\n",
    "                break\n",
    "            elif key == ord(\"t\"):\n",
    "                calibr.get_frame()\n",
    "            elif key == ord(\"f\"):\n",
    "                displaying = calibr.process_charuko(cam_img)\n",
    "    finally:\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(calibr.captured_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibr.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(123)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('robotict')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "41a017ecc4e6dcc4d88185cf7e3fda52cf080bfc71da177df7130c68847d7b14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
